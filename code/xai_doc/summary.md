ご依頼ありがとうございます。アップロードいただいたXAI（説明可能なAI）関連の論文サマリーに基づき、主要な手法の特性、数式、有効性、長所/短所、および他の手法との違いをまとめます。

---

## 勾配および特徴マップに基づく手法 (主にCNN向け)

### 1. Saliency Maps (顕著性マップ)

* **概要**:
    最も基本的なXAI手法の一つで、特定のクラス予測スコアに対して、入力画像の各ピクセルがどれだけ影響を与えたか（感度）を可視化します。
* **手法**:
    クラス $c$ のスコア関数を $S_c(x)$ としたとき、入力画像 $x$ に対する勾配を計算します。
    $$
    W^{(c)}(x) = \nabla_x S_c(x)
    $$
    通常、ヒートマップは各ピクセル $(i,j)$ でのRGBチャンネル間の勾配の絶対値の最大値で構成されます:
    $$
    M^{(c)}(i,j) = \max_{k\in\{R,G,B\}} \left| \frac{\partial S_c(x)}{\partial x_{i,j,k}} \right|
    $$
* **有効性/Usecase**:
    モデルが画像のどの領域を「見て」判断したかの基本的な理解や、弱教師ありでの物体局在タスクに使用されます。
* **Pros/Cons**:
    * **Pros**: 計算が高速で実装が非常にシンプルです。
    * **Cons**: 勾配が飽和する領域（例：ReLUの通過後）では感度がゼロになり、予測に重要でも検出できないことがあります。また、ノイズが多い傾向があります。
* **他の指標との違い**:
    CAM/Grad-CAMがクラス判別的な領域に焦点を当てるのに対し、Saliency Mapは純粋な入力感度を示します。LRPやIGは、この手法の勾配飽和問題を解決するために開発されました。

### 2. DeconvNet (デコンボリューションネットワーク)

* **概要**:
    モデルの予測結果ではなく、CNNの中間層にあるフィルタ（特徴マップ）が入力画像のどのようなパターンを学習・検出しているかを可視化する手法です。
* **手法**:
    CNNの順伝播（畳み込み、ReLU、プーリング）を近似的に逆方向に辿ります。
    1.  **Unpooling**: 順伝播のMax-Pooling時に最大値だった位置（switch）を記憶しておき、その位置にのみ値を戻します。
    2.  **Rectification**: 逆伝播時もReLUを適用し、負の値を遮断します。
    3.  **Deconvolution**: 畳み込みフィルタを転置したもの（$W_{\ell}^{\top}$）を使って逆畳み込みを行います。
* **有効性/Usecase**:
    モデルのデバッグ、アーキテクチャ設計の改善、中間層の挙動理解に使用されます。
* **Pros/Cons**:
    * **Pros**: フィルタがどのような視覚的パターン（テクスチャ、形状など）に反応するかを具体的に示せます。
    * **Cons**: 生成される可視化は、特定のクラス予測に直接結びついたものではありません。
* **他の指標との違い**:
    Saliency MapやGrad-CAMが「特定の予測に対する入力の寄与」を説明するのに対し、DeconvNetは「モデルが学習した内部フィルタの機能」を説明します。

### 3. CAM (Class Activation Mapping)

* **概要**:
    CNNがクラスを識別するために画像のどの領域に注目しているかを特定する、クラス判別的な局在マップを生成します。
* **手法**:
    アーキテクチャに制約があり、最終畳み込み層の後にGlobal Average Pooling (GAP) と線形分類層（Softmax）が続く必要があります。クラス $c$ の線形重みを $w_k^c$、最終畳み込み層の特徴マップを $A^k$ とすると、CAMは以下の式で計算されます:
    $$
    M^{c}(i,j) = \sum_{k} w_k^{c} A^{k}_{ij}
    $$
* **有効性/Usecase**:
    画像レベルのラベルのみで学習したモデルでも、物体の位置を特定（弱教師あり局在）できます。
* **Pros/Cons**:
    * **Pros**: クラス判別性が高く、粗いながらも正確な局在が可能です。
    * **Cons**: モデルのアーキテクチャがGAP + 線形層に限定されます。
* **他の指標との違い**:
    Grad-CAMは、このCAMのアイデアを勾配を用いることで一般化し、アーキテクチャの制約をなくしたものです。

### 4. Grad-CAM (Gradient-weighted Class Activation Mapping)

* **概要**:
    CAMを一般化し、アーキテクチャの変更なしに、任意のCNNモデルに対してクラス判別的な可視化（ヒートマップ）を生成する手法です。
* **手法**:
    最終畳み込み層の特徴マップ $A^k$ に対するクラススコア $y^c$ の勾配を計算し、それを空間的に平均して各特徴マップの重要度（重み） $\alpha_k^c$ を求めます。
    $$
    \alpha_k^{c} = \frac{1}{Z} \sum_{i} \sum_{j} \frac{\partial y^{c}}{\partial A^{k}_{ij}} \quad (\text{Zはピクセル数})
    $$
    これら重みを用いて特徴マップを線形結合し、ReLUを適用してヒートマップを生成します:
    $$
    L^{c}_{\text{Grad-CAM}} = \operatorname{ReLU}\left( \sum_{k} \alpha_k^{c} A^{k} \right)
    $$
* **有効性/Usecase**:
    分類モデルの失敗解析、バイアスの検出、VQA（視覚的質問応答）や画像キャプション生成モデルの説明にも適用可能です。
* **Pros/Cons**:
    * **Pros**: CAMの一般化であり、再学習やアーキテクチャ変更が不要。クラス判別的。
    * **Cons**: CAM同様、ヒートマップの解像度は最終畳み込み層に依存するため粗くなります。
* **他の指標との違い**:
    CAMのアーキテクチャ制約を解消しました。Guided Backpropagation（Saliency Mapの一種）と組み合わせることで、高解像度かつクラス判別的な「Guided Grad-CAM」を生成できます。

---

## 伝播および公理に基づく手法

### 5. LRP (Layer-Wise Relevance Propagation)

* **概要**:
    「関連性保存の法則」に基づき、モデルの出力スコア（関連性）を、ネットワークの層を逆方向に辿って入力特徴量に分配する手法です。
* **手法**:
    ある層のニューロン $k$ が持つ関連性 $R_k$ を、そのニューロンの活性化に貢献した下の層のニューロン $j$ に分配します。基本的な伝播ルールは以下の通りです:
    $$
    R_j = \sum_k \frac{z_{jk}}{\sum_{j'} z_{j'k}} R_k
    $$
    ここで $z_{jk} = a_j w_{jk}$（$a_j$: 下層の活性化、 $w_{jk}$: 重み）は貢献度を表します。予測を促進する貢献（正）と抑制する貢献（負）を分けて伝播する $\alpha, \beta$-ルールなど、複数のルールが提案されています。
* **有効性/Usecase**:
    モデルのデバッグ、医療画像診断など、判断根拠の透明性が求められる分野で使用されます。
* **Pros/Cons**:
    * **Pros**: 理論的妥当性（関連性保存則）があり、Saliency Mapよりノイズの少ないヒートマップを生成できます。
    * **Cons**: 伝播ルールの選択（$\epsilon$-ルール, $\alpha, \beta$-ルールなど）が必要であり、実装によって結果が異なる場合があります。
* **他の指標との違い**:
    Saliency Map（感度分析）とは異なり、出力値を厳密に入力に分配する「保存則」を満たします。

### 6. Integrated Gradients (IG)

* **概要**:
    「感度(Sensitivity)」と「実装不変性(Implementation Invariance)」という2つの公理を定義し、これらを満たす手法として提案されました。Saliency Mapの勾配飽和問題を解決します。
* **手法**:
    ベースライン入力 $x'$（例：黒い画像）から実際入力 $x$ までの直線経路上の勾配を積分（累積）します。特徴量 $i$ の寄与度は以下の式で定義されます:
    $$
    \text{IntegratedGrads}_i(x) = (x_i - x'_i) \times \int_{\alpha=0}^{1} \frac{\partial F(x' + \alpha(x - x'))}{\partial x_i} d\alpha
    $$
    また、アトリビューションの総和が $F(x) - F(x')$ に一致する「完全性(Completeness)」の性質も満たします。
* **有効性/Usecase**:
    モデルのデバッグ、学習済みルール抽出、医療診断など、信頼性が重要なタスクで広く利用されます。
* **Pros/Cons**:
    * **Pros**: 強力な公理的基盤を持つ（感度、実装不変性、完全性）。勾配が飽和する領域でも寄与を計算できます。
    * **Cons**: ベースライン $x'$ の選択に結果が依存します。
* **他の指標との違い**:
    単純な勾配法（Saliency）が満たせない「感度」公理を満たします。LRPやDeepLIFTが満たせない「実装不変性」公理を満たします。

### 7. DeepLIFT (Learning Important Features Through Propagating Activation Differences)

* **概要**:
    IGと同様にベースライン入力 $x_0$ を使用し、実際の入力 $x$ との「差分」に着目します。出力の差分 $\Delta f = f(x)-f(x_0)$ を、入力の差分 $\Delta x_i$ の貢献度の総和 $\sum_{i} C_{\Delta x_i \to \Delta f}$ として厳密に分解（完全性）します。
* **手法**:
    各ニューロンの活性化差分を、その入力ニューロンの差分に分配します。この分配比率を「マルチプライヤ」と呼びます。勾配の代わりにこのマルチプライヤを用いることで、勾配が0になる領域（ReLUの飽和域など）でも貢献度を伝播できます。
* **有効性/Usecase**:
    ゲノミクス解析など、飽和領域での挙動が重要な分野で使用されます。
* **Pros/Cons**:
    * **Pros**: 勾配飽和に強い。計算が高速（単一の逆伝播で計算可能）。完全性を満たす。
    * **Cons**: ベースラインの選択に敏感です。
* **他の指標との違い**:
    IGの積分計算を、単一の参照点との差分で近似したものと解釈できます。LRPとは異なり、参照点との「差分」を伝播させます。

---

## モデル非依存・サロゲート手法

### 8. LIME (Local Interpretable Model-agnostic Explanations)

* **概要**:
    「なぜこの予測を信頼すべきか？」に答えるため、任意のブラックボックス分類器 $f$ の予測を、局所的に（入力 $x$ の近傍で）模倣する、単純で解釈可能なモデル $g$（例：スパース線形モデル）を学習する手法です。
* **手法**:
    説明したい入力 $x$ の近傍で、入力をランダムに摂動（例：単語を隠す、画像のスーパーピクセルを消す）させたサンプル $z_i$ を生成し、それらに対する $f$ の予測値を取得します。
    これらのサンプル群を用いて、元の入力 $x$ に近いサンプルほど重み $\pi_x(z_i)$ が大きくなるように重み付き線形回帰などを行い、局所的な説明モデル $g$ を獲得します。
    $$
    \xi(x) = \underset{g \in \mathcal{G}}{\arg\min} \sum_{i} \pi_x(z_i)\,\bigl( f(z_i) - g(z_i') \bigr)^2 + \Omega(g)
    $$
* **有効性/Usecase**:
    画像、テキスト、表形式データなど、あらゆるモデル（NN、SVM、ランダムフォレスト等）の説明に適用可能です。
* **Pros/Cons**:
    * **Pros**: モデル非依存（ブラックボックスに適用可）、人間が理解しやすい（例：「この単語があるから」）。
    * **Cons**: サンプリング方法や近傍の定義（重み付け）によって説明が不安定になることがあります。
* **他の指標との違い**:
    Grad-CAMやIGなどがモデル内部（勾配や構造）にアクセスする「ホワイトボックス」手法であるのに対し、LIMEはモデルの入出力のみを使用する「ブラックボックス」手法です。

### 9. SHAP (SHapley Additive exPlanations)

* **概要**:
    LIMEやDeepLIFTなどの既存手法を統一する理論的枠組みであり、ゲーム理論のシャープレイ値に基づいて、予測に対する各特徴量の貢献度 $\phi_i$ を公平に分配する手法です。
* **手法**:
    特徴量の貢献度 $\phi_i$ が「局所正確性（Local Accuracy）」「欠落性（Missingness）」「一貫性（Consistency）」の3つの公理を満たす唯一の解としてシャープレイ値を定義します。
    $$
    g(x') = \phi_0 + \sum_{i=1}^{M} \phi_i x'_i \quad (\text{ここで } f(x) = g(x') )
    $$
    シャープレイ値 $\phi_i$ は、特徴量 $i$ が参加する全ての可能な特徴量の組み合わせ（サブセット）における、その特徴量の限界貢献度を平均したものです。
* **有効性/Usecase**:
    個々の予測の説明からモデル全体の挙動理解まで、幅広く使用されます。特に木ベースのモデル（TreeSHAP）や深層学習（DeepSHAP）で効率的に計算できます。
* **Pros/Cons**:
    * **Pros**: 強力な理論的基盤（公理を満たす唯一の加法的説明）を持つ。多くの既存手法を統一する枠組みを提供します。
    * **Cons**: 汎用的な計算（KernelSHAP）は計算コストが非常に高い。ベースライン（背景分布）の選択が必要です。
* **他の指標との違い**:
    LIMEの局所サロゲートアプローチを、シャープレイ値の観点から厳密に定式化したものがKernelSHAPです。DeepLIFTはDeepSHAPによってシャープレイ値の高速な近似計算手法として関連付けられました。

---

## 概念ベース・データベースの手法

### 10. TCAV (Testing with Concept Activation Vectors)

* **概要**:
    ピクセルや単語といった低レベルな特徴量ではなく、人間が理解可能な高レベルな「概念」（例：「ストライプ模様」「性別」）が、モデルの予測にどれだけ影響を与えているかを定量化する手法です。
* **手法**:
    1.  ユーザーが概念（例：「ストライプ」）の例画像と、対照（ランダム）画像を用意します。
    2.  これらをモデルの中間層 $f_{\ell}$ に通し、得られた活性化ベクトルを線形識別器で分離します。
    3.  この識別器の法線ベクトルを「概念活性化ベクトル（CAV）」$v_C$ とします。
    4.  あるクラス $k$ のスコア $S_k$ の、CAV $v_C$ 方向への方向微分 $D_{k,\ell}^{(C)}(x) = \nabla_{f_{\ell}} S_k(x) \cdot v_C$ を計算します。
    5.  TCAVスコアは、クラス $k$ のデータセット全体で、この方向微分が正になるサンプル（＝概念 $C$ がクラス $k$ に寄与）の割合として定義されます。
* **有効性/Usecase**:
    ドメイン知識（例：医療における「しこりの形状」）とモデルの内部表現を結びつけるのに役立ちます。
* **Pros/Cons**:
    * **Pros**: 人間が理解しやすい「概念」レベルでの説明が可能。統計的検定により、概念の寄与が偶然でないかを確認できます。
    * **Cons**: 概念を定義するための例画像と対照画像の収集が必要です。
* **他の指標との違い**:
    他の手法が「入力特徴量」の寄与を測るのに対し、TCAVは「高レベルな概念」の寄与をグローバルに（データセット全体で）測ります。

### 11. Influence Functions (影響関数)

* **概要**:
    特定入力の「特徴量」ではなく、「どの訓練データ」がモデルの特定の予測に影響を与えたかを定量化する手法です。
* **手法**:
    ロバスト統計学の影響関数に基づき、ある訓練点 $z$ の重みを微小に変化させた（または削除した）場合に、テスト点 $z_{\text{test}}$ の損失がどれだけ変化するかを近似計算します。
    $$
    \mathcal{I}_{\text{up, loss}}(z, z_{\text{test}}) = - \nabla_{\theta} L(z_{\text{test}})^{\top} H_{\hat{\theta}}^{-1} \nabla_{\theta} L(z)
    $$
    $H_{\hat{\theta}}$ はモデルパラメータ $\theta$ に関する損失のヘッセ行列です。
* **有効性/Usecase**:
    モデルのデバッグ、データセット内の誤ラベル検出、データ汚染（ポイズニング攻撃）の特定に使用されます。
* **Pros/Cons**:
    * **Pros**: 予測の根拠を「訓練事例」で示せるため、非常に直感的です。
    * **Cons**: ヘッセ逆行列 $H^{-1}$ の計算（または近似）にコストがかかります。理論は凸関数を前提としており、深層学習のような非凸モデルでは近似に留まります。
* **他の指標との違い**:
    他のすべての手法が「入力特徴量」の寄与を説明するのに対し、影響関数は「訓練データ点」の寄与を説明する点で根本的に異なります。