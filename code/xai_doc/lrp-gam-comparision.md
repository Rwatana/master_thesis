GAM（一般化加法モデル）と LRP（Layer-wise Relevance Propagation）は,どちらも XAI（説明可能な AI）の手法ですが,**根本的な思想と使用場面が全く異なります**。

- **GAM:** モデル自体が「透明」であるように**設計**する（_Glass-box_ / 透明ボックス）
- **LRP:** 既存の「不透明な」モデルの**中身を後から解析**する（_Post-hoc_ / 事後説明）

この 2 つの特性を踏まえて,それぞれ詳しく解説します。

---

## 🏛️ GAM (一般化加法モデル)

GAM は,「解釈可能性」を最優先して設計された統計モデルです。

### 利点 (Pros) と 欠点 (Cons)

|                 | 説明                                                                                                                                                                                                                                                                                                                                                                                                                        |
| :-------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **利点 (Pros)** | **1. 圧倒的な解釈可能性:** 各特徴量$x_i$が予測にどう貢献しているか（$f_i(x_i)$）を完全に分離して可視化できます。「年齢が 30 歳から 50 歳にかけてスコアが上がり,その後下がる」といった非線形な関係性をグラフで明確に理解できます。<br>**2. 非線形性の獲得:** 単純な線形回帰よりも高い予測性能を持ちます。<br>**3. "Why" の説明:** 「なぜ」その予測になったのか,どの特徴量がどれだけ（正に/負に）貢献したかを数値で示せます。 |
| **欠点 (Cons)** | **1. 予測性能の限界:** 特徴量同士の複雑な「相互作用」を捉えるのが苦手です。そのため,XGBoost やニューラルネットワークのようなブラックボックスモデルに比べ,純粋な予測精度では劣ることが多いです。<br>**2. 適用先の限界:** 主に\*\*構造化データ（表形式データ）\*\*で使われ,画像やテキストなどの非構造化データには直接適用できません。                                                                                         |

### 使用できる時・できない時 と 具体例

|                    | 説明                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |
| :----------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **使用できる時**   | **「なぜ」その予測になったのかを説明する責任が重い場面。**<br><br> **具体例:**<br> 1. **金融（与信審査）:** 顧客のローン申請を「なぜ」拒否したのかを,金融当局や本人に明確に説明する必要がある時。GAM なら「$f(\text{年齢})$のスコアは+5 点でしたが,$f(\text{負債額})$のスコアが-20 点だったため」と説明できます。<br> 2. **医療（発症予測）:** 患者の検査結果から「5 年後の発症確率」を予測する際,どの検査項目（特徴量）がリスク要因になっているかを医師が理解し,患者に説明する必要がある時。 |
| **使用できない時** | **解釈性よりも,1%でも高い予測性能が求められる場面。または,非構造化データを扱う時。**<br><br> **具体例:**<br> 1. **画像認識:** 自動運転車が「歩行者」を認識する時。なぜ歩行者と認識したか（LRP の出番）も重要ですが,それ以前に 99.999%の精度で認識することが最優先されます。<br> 2. **自然言語処理:** 高度なチャットボットが文脈を理解する時。単語間の複雑すぎる相互作用が重要であり,GAM の「加法性」という制約では性能が出ません。                                                            |

---

## 🧠 LRP (Layer-wise Relevance Propagation)

LRP は,すでに学習済みの**ニューラルネットワーク (NN)** というブラックボックスモデルを「こじ開けて」中身を覗き見るための解析手法です。

### $z_{ij}$ とは何か？

LRP を理解する上で,$z_{ij}$は非常に重要な概念です。

$$
z_{ij} = w_{ij} x_i
$$  * **$x_i$:** 第$l$層にあるニューロン$i$の\*\*活性値（出力）\*\*です。
* **$w_{ij}$:** 第$l$層のニューロン$i$から,次の第$l+1$層のニューロン$j$へと伸びる接続の**重み**です。
* **$z_{ij}$:** $x_i$と$w_{ij}$を掛け合わせたもので,これは\*\*「ニューロン$i$が,次の層のニューロン$j$に対して送る『貢献の素』」\*\*と解釈できます。

**具体例（選挙の比喩）:**

* 第$l+1$層のニューロン$j$を「候補者」だとします。
* 第$l$層のニューロン$i$たちは「有権者」です。
* 各有権者$i$は,自分の「意見の強さ（活性値$x_i$）」を持っています。
* 候補者$j$は,有権者$i$からの「票の重み（重み$w_{ij}$）」を持っています。
* \*\*$z_{ij}$**は,有権者$i$が候補者$j$に投じる**「加重された一票」\*\*です。
* 候補者$j$は,全員からの加重票の合計（$z_j = \sum_i z_{ij}$）を受け取り,最終的な自分の「当選スコア（次の活性値）」を決めます。

LRPの逆伝播は,この$z_{ij}$の「貢献度合い」に応じて,候補者$j$が持つ「関連度（当選の要因）」を有権者$i$たちに分配していくプロセスです。

### 利点 (Pros) と 欠点 (Cons)

| | 説明 |
| :--- | :--- |
| **利点 (Pros)** | **1. ブラックボックスの解析:** すでに高性能を発揮しているCNNやNNの「判断根拠」を可視化できます。<br>**2. 入力層への帰着:** 予測の根拠を,元の入力（例：画像のどのピクセルか）まで遡って特定できます。<br>**3. ルールの柔軟性:** $\alpha\beta$-LRPルールなどを使うことで,「予測にポジティブに効いた要因だけ」を抽出するなど,目的に応じた分析が可能です。 |
| **欠点 (Cons)** | **1. あくまで「事後説明」:** LRPが示すヒートマップは,モデルの挙動を**近似・解釈したもの**であり,モデルの「真の思考プロセス」そのものではありません。ルールの選び方で結果が変わることもあります。<br>**2. 解釈の難しさ:** GAMと違い,「なぜ」を直感的なグラフ（$f(x)$）で示せません。得られるのは「このピクセルが重要だった」というヒートマップであり,そのピクセルが*どう*重要だったのか（例：明るいとスコアが上がるのか,暗いと上がるのか）は,追加の分析が必要です。 |

### 使用できる時・できない時 と 具体例

| | 説明 |
| :--- | :--- |
| **使用できる時** | **高性能なブラックボックスモデル（特にNN）をすでに持っており,その「特定の予測」の根拠を知りたい時。**<br><br> **具体例:**<br> 1. **医療画像（CNN）:** AIが「このレントゲン写真には腫瘍の疑いがある」と予測した時。LRPを使ってヒートマップを生成し,AIが画像の**どの領域を見て**そう判断したのかを可視化します。医師はそれを見て,AIが妥当な場所（腫瘍らしき影）を見ているか,無関係なノイズを見ているかを確認できます。<br> 2. **デバッグ:** AIが「猫」の画像を「犬」と誤認識した時。LRPで可視化すると,猫の耳ではなく,背景に写り込んだ「テニスボール」に強く反応していた,といった原因究明に使えます。 |
| **使用できない時** | **モデルの「全体的な挙動」をシンプルに説明したい時。または,NN以外のモデル（決定木,SVMなど）を説明したい時。**<br><br> **具体例:**<br> 1. **銀行のローン審査:** （GAMの例と同じ）LRPで「この顧客は入力特徴量Aが重要だった」とヒートマップで見せられても,「だから何故スコアが低いのか」が直感的に分かりません。GAMの$f(x)$のグラフの方が遥かに明確です。<br> 2. **ランダムフォレストの分析:** LRPはNNの層構造を逆伝播する前提で設計されているため,決定木ベースのモデルには（そのままでは）適用できません。（その場合はSHAPなどの別手法が使われます） |
$$
