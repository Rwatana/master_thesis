import polars as pl
import os
from datetime import datetime

# --- è¨­å®š ---
INPUT_FILE = 'preprocessed_posts_detailed.csv'

# å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å
FILE_A = 'dataset_A_active_all.csv'
FILE_B = 'dataset_B_medium_rich.csv'
FILE_C = 'dataset_C_rich_only.csv'

def generate_three_datasets_fast():
    print(f"ğŸš€ [M1 Ultra Optimized] Starting Multi-Dataset Generation...")
    
    if not os.path.exists(INPUT_FILE):
        print(f"âŒ Error: Input file not found: {INPUT_FILE}")
        return

    start_time = datetime.now()

    # ---------------------------------------------------------
    # Step 1: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ©ãƒ³ã‚¯ã®åˆ¤å®š (Lazyãƒ¢ãƒ¼ãƒ‰ã§ä¸¦åˆ—ã‚¹ã‚­ãƒ£ãƒ³)
    # ---------------------------------------------------------
    print("   Step 1: Analyzing user activity levels (Jan-Nov 2017)...")
    
    # å­¦ç¿’æœŸé–“ã®è¨­å®š
    hist_start = datetime(2017, 1, 1)
    hist_end = datetime(2017, 11, 30, 23, 59, 59)

    # LazyFrameã‚’ä½¿ç”¨ã—ã¦ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã ã‘ã‚’ã¾ãšã‚¹ã‚­ãƒ£ãƒ³
    q = (
        pl.scan_csv(INPUT_FILE, low_memory=False, rechunk=False)
        .with_columns(pl.col("datetime").str.to_datetime())
        .filter((pl.col("datetime") >= hist_start) & (pl.col("datetime") <= hist_end))
        .group_by("username")
        .agg(
            pl.col("datetime").dt.month().n_unique().alias("active_months")
        )
    )
    
    # åˆ¤å®šå®Ÿè¡Œ (ã“ã“ã§å…¨ã‚³ã‚¢ãŒå›ã‚Šã¾ã™)
    user_stats = q.collect(streaming=True)

    # å„ã‚°ãƒ«ãƒ¼ãƒ—ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒªã‚¹ãƒˆã‚’å–å¾—
    rich_users = user_stats.filter(pl.col("active_months") >= 9).get_column("username").unique()
    medium_users = user_stats.filter((pl.col("active_months") >= 4) & (pl.col("active_months") < 9)).get_column("username").unique()
    sparse_users = user_stats.filter((pl.col("active_months") >= 1) & (pl.col("active_months") < 4)).get_column("username").unique()

    # ã‚»ãƒƒãƒˆã®æ§‹ç¯‰
    # Polarsã®is_inã¯éå¸¸ã«é«˜é€Ÿãªã®ã§ã€é›†åˆæ¼”ç®—ã‚’ä½¿ã‚ãšãã®ã¾ã¾æ¸¡ã›ã¾ã™
    list_A = pl.concat([rich_users, medium_users, sparse_users])
    list_B = pl.concat([rich_users, medium_users])
    list_C = rich_users

    print(f"   ğŸ“Š User Stats:")
    print(f"      - Rich   : {len(rich_users):,} users")
    print(f"      - Medium : {len(medium_users):,} users")
    print(f"      - Sparse : {len(sparse_users):,} users")

    # ---------------------------------------------------------
    # Step 2: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æŠ½å‡ºã¨æ›¸ãå‡ºã—
    # ---------------------------------------------------------
    print("\n   Step 2: Processing and writing datasets...")

    # ãƒ¡ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ (128GB RAMã‚’æ´»ã‹ã—ã¦ãƒ¡ãƒ¢ãƒªã«è¼‰ã›ã‚‹)
    # ã‚‚ã—CSVãŒ100GBã‚’è¶…ãˆã‚‹å ´åˆã¯ streaming=True ã‚’ç¶­æŒã—ã¾ã™
    df_full = pl.read_csv(INPUT_FILE, low_memory=False)

    # Dataset A (Emptyä»¥å¤–å…¨ã¦)
    print(f"      -> Writing {FILE_A}...")
    df_A = df_full.filter(pl.col("username").is_in(list_A))
    df_A.write_csv(FILE_A)
    print(f"         Total rows: {len(df_A):,}")

    # Dataset B (Medium + Rich)
    print(f"      -> Writing {FILE_B}...")
    df_B = df_A.filter(pl.col("username").is_in(list_B)) # df_Aã‹ã‚‰çµã‚Šè¾¼ã‚€ã“ã¨ã§é«˜é€ŸåŒ–
    df_B.write_csv(FILE_B)
    print(f"         Total rows: {len(df_B):,}")

    # Dataset C (Rich only)
    print(f"      -> Writing {FILE_C}...")
    df_C = df_B.filter(pl.col("username").is_in(list_C)) # df_Bã‹ã‚‰çµã‚Šè¾¼ã‚€ã“ã¨ã§é«˜é€ŸåŒ–
    df_C.write_csv(FILE_C)
    print(f"         Total rows: {len(df_C):,}")

    end_time = datetime.now()
    duration = end_time - start_time
    print(f"\nâœ… All Done! Process took: {duration}")

if __name__ == "__main__":
    generate_three_datasets_fast()