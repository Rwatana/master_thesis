import streamlit as st
import pandas as pd

st.set_page_config(page_title="å…¨ä½“ è¶Šå¢ƒãƒ¡ãƒ³ã‚·ãƒ§ãƒ³åˆ†æ", layout="wide")

# --- ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿é–¢æ•° ---
@st.cache_data
def load_mention_data(filepath):
    """ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€"""
    try:
        df = pd.read_csv(filepath, header=0, names=['username', 'mention', 'timestamp'])
        df['datetime'] = pd.to_datetime(df['timestamp'], unit='s')
        return df.drop(columns=['timestamp'])
    except FileNotFoundError:
        st.error(f"ãƒ•ã‚¡ã‚¤ãƒ« '{filepath}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return None

@st.cache_data
def load_influencer_data(filepath):
    """influencers.txtã‚’èª­ã¿è¾¼ã‚€"""
    try:
        return pd.read_csv(filepath, sep='\t', skiprows=[1])
    except FileNotFoundError:
        return None

# --- å…¨ãƒšã‚¢è¨ˆç®—é–¢æ•° ---
@st.cache_data
def calculate_all_cross_mentions(df_mentions, df_influencers):
    """
    å…¨ã¦ã®ç•°ã‚«ãƒ†ã‚´ãƒªé–“ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ã‚’æŠ½å‡ºã—ã€è©³ç´°ãƒšã‚¢ã¨å€‹äººã‚µãƒãƒªãƒ¼ã®2ã¤ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆã™ã‚‹ã€‚
    """
    if df_mentions is None or df_influencers is None:
        return pd.DataFrame(), pd.DataFrame()

    df_merged = pd.merge(df_mentions, df_influencers[['Username', 'Category']], left_on='username', right_on='Username', how='inner').rename(columns={'Category': 'mentioner_category'})
    df_merged = pd.merge(df_merged, df_influencers[['Username', 'Category']], left_on='mention', right_on='Username', how='inner').rename(columns={'Category': 'mentioned_category'})
    cross_category_df = df_merged[df_merged['mentioner_category'] != df_merged['mentioned_category']]

    # 1. è©³ç´°ãƒšã‚¢ãƒ†ãƒ¼ãƒ–ãƒ«ã®ä½œæˆ
    pair_summary = cross_category_df.groupby(['mention', 'mentioned_category', 'mentioner_category']).agg(
        total_mentions=('username', 'count'),
        unique_mentioners=('username', 'nunique')
    ).reset_index()
    pair_summary.rename(columns={
        'mention': 'ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ã•ã‚ŒãŸãƒ¦ãƒ¼ã‚¶ãƒ¼', 'mentioned_category': 'è‡ªåˆ†ã®ã‚«ãƒ†ã‚´ãƒª',
        'mentioner_category': 'ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³å…ƒã®ã‚«ãƒ†ã‚´ãƒª', 'total_mentions': 'åˆè¨ˆãƒ¡ãƒ³ã‚·ãƒ§ãƒ³å›æ•°',
        'unique_mentioners': 'ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªãƒ¡ãƒ³ã‚·ãƒ§ãƒ³å…ƒã®äººæ•°'
    }, inplace=True)
    
    # 2. å€‹äººã‚µãƒãƒªãƒ¼ãƒ†ãƒ¼ãƒ–ãƒ«ã®ä½œæˆ
    personal_summary = cross_category_df.groupby('mention').agg(
        total_cross_mentions=('username', 'count'),
        unique_cross_mentioners=('username', 'nunique'),
        unique_cross_categories=('mentioner_category', 'nunique')
    ).reset_index()
    personal_summary.rename(columns={
        'mention': 'ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ã•ã‚ŒãŸãƒ¦ãƒ¼ã‚¶ãƒ¼', 'total_cross_mentions': 'ç•°åˆ†é‡ã‹ã‚‰ã®ç·ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³æ•°',
        'unique_cross_mentioners': 'ç•°åˆ†é‡ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°', 'unique_cross_categories': 'ç•°åˆ†é‡ã®ã‚«ãƒ†ã‚´ãƒªæ•°'
    }, inplace=True)
    
    # å€‹äººã‚µãƒãƒªãƒ¼ã«æœ¬äººã®ã‚«ãƒ†ã‚´ãƒªæƒ…å ±ã‚’è¿½åŠ 
    personal_summary = pd.merge(personal_summary, df_influencers[['Username', 'Category']], left_on='ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ã•ã‚ŒãŸãƒ¦ãƒ¼ã‚¶ãƒ¼', right_on='Username', how='left')
    
    return pair_summary.sort_values(['ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ã•ã‚ŒãŸãƒ¦ãƒ¼ã‚¶ãƒ¼', 'åˆè¨ˆãƒ¡ãƒ³ã‚·ãƒ§ãƒ³å›æ•°'], ascending=[True, False]), personal_summary.sort_values('ç•°åˆ†é‡ã‹ã‚‰ã®ç·ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³æ•°', ascending=False)


# --- UIæç”» ---
st.title("ğŸŒ å…¨ä½“ è¶Šå¢ƒãƒ¡ãƒ³ã‚·ãƒ§ãƒ³åˆ†æ")
st.info("å„ã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼ãŒã€ã©ã®ã‚«ãƒ†ã‚´ãƒªã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã€ã©ã‚Œã ã‘å¤šãã®æ³¨ç›®ï¼ˆãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ï¼‰ã‚’é›†ã‚ã¦ã„ã‚‹ã‹ã‚’åˆ†æã—ã¾ã™ã€‚")

# --- ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ ---
df_mentions = load_mention_data('output_mentions_all_parallel.csv')
df_influencers = load_influencer_data('influencers.txt')

with st.spinner("å…¨ä½“ã®è¶Šå¢ƒãƒ¡ãƒ³ã‚·ãƒ§ãƒ³é–¢ä¿‚ã‚’è¨ˆç®—ä¸­..."):
    pair_summary_df, personal_summary_df = calculate_all_cross_mentions(df_mentions, df_influencers)

if pair_summary_df.empty:
    st.warning("ç•°ã‚«ãƒ†ã‚´ãƒªé–“ã®ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
    st.stop()
    
# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ ---
st.sidebar.header("ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼")

# â–¼â–¼â–¼ ä¿®æ­£ç‚¹: ãƒ¦ãƒ¼ã‚¶ãƒ¼çµã‚Šè¾¼ã¿ã‚’è¿½åŠ  â–¼â–¼â–¼
all_users = sorted(pair_summary_df['ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ã•ã‚ŒãŸãƒ¦ãƒ¼ã‚¶ãƒ¼'].unique())
selected_user = st.sidebar.selectbox(
    "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã§çµã‚Šè¾¼ã‚€ (ä»»æ„):",
    options=['ï¼ˆå…¨ã¦ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ï¼‰'] + all_users,
    index=0 # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ã€Œå…¨ã¦ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã€
)

# ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒé¸æŠã•ã‚ŒãŸå ´åˆã€ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
if selected_user != 'ï¼ˆå…¨ã¦ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ï¼‰':
    pair_summary_df = pair_summary_df[pair_summary_df['ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ã•ã‚ŒãŸãƒ¦ãƒ¼ã‚¶ãƒ¼'] == selected_user]
    personal_summary_df = personal_summary_df[personal_summary_df['ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ã•ã‚ŒãŸãƒ¦ãƒ¼ã‚¶ãƒ¼'] == selected_user]
# â–²â–²â–² ä¿®æ­£ç‚¹ â–²â–²â–²

all_categories = sorted(pair_summary_df['è‡ªåˆ†ã®ã‚«ãƒ†ã‚´ãƒª'].unique())
selected_my_category = st.sidebar.multiselect(
    "è‡ªåˆ†ã®ã‚«ãƒ†ã‚´ãƒªã§çµã‚Šè¾¼ã¿:",
    options=all_categories,
    default=all_categories
)

if not selected_my_category:
    st.warning("å°‘ãªãã¨ã‚‚1ã¤ã®ã‚«ãƒ†ã‚´ãƒªã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
    st.stop()
    
# ã‚«ãƒ†ã‚´ãƒªã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
pair_summary_df = pair_summary_df[pair_summary_df['è‡ªåˆ†ã®ã‚«ãƒ†ã‚´ãƒª'].isin(selected_my_category)]
personal_summary_df = personal_summary_df[personal_summary_df['Category'].isin(selected_my_category)]


# --- ãƒ¡ã‚¤ãƒ³ç”»é¢ ---

# â–¼â–¼â–¼ æ–°ã—ã„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’è¿½åŠ  â–¼â–¼â–¼
st.header("ã‚µãƒãƒªãƒ¼ï¼šèª°ãŒåˆ†é‡ã‚’è¶…ãˆã¦æ³¨ç›®ã•ã‚Œã¦ã„ã‚‹ã‹")
st.write("å„ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã€ç•°åˆ†é‡ã‹ã‚‰å—ã‘ãŸç·ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³æ•°ã€ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°ã€ã‚«ãƒ†ã‚´ãƒªæ•°ã®é›†è¨ˆã§ã™ã€‚")
st.dataframe(personal_summary_df[['ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ã•ã‚ŒãŸãƒ¦ãƒ¼ã‚¶ãƒ¼', 'Category', 'ç•°åˆ†é‡ã‹ã‚‰ã®ç·ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³æ•°', 'ç•°åˆ†é‡ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°', 'ç•°åˆ†é‡ã®ã‚«ãƒ†ã‚´ãƒªæ•°']], use_container_width=True)
# â–²â–²â–² æ–°ã—ã„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ â–²â–²â–²


st.markdown("---")
st.header("è©³ç´°ï¼šã©ã®åˆ†é‡ã‹ã‚‰æ³¨ç›®ã•ã‚Œã¦ã„ã‚‹ã‹")
st.write(f"åˆè¨ˆ **{len(pair_summary_df)}** ãƒ‘ã‚¿ãƒ¼ãƒ³ã®è¶Šå¢ƒãƒ¡ãƒ³ã‚·ãƒ§ãƒ³é–¢ä¿‚ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚")
st.dataframe(pair_summary_df, use_container_width=True)