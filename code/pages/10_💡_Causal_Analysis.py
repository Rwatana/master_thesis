import streamlit as st
import pandas as pd
import os
import plotly.express as px
import plotly.graph_objects as go
import numpy as np
from sklearn.linear_model import LinearRegression
from datetime import timedelta

st.set_page_config(page_title="æˆé•·è¦å› åˆ†æ", layout="wide")

# --- ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿é–¢æ•° ---
@st.cache_data
def load_posts_data(filepath):
    try:
        return pd.read_csv(filepath, parse_dates=['datetime'])
    except FileNotFoundError:
        st.error(f"ãƒ•ã‚¡ã‚¤ãƒ« '{filepath}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return None

@st.cache_data
def load_hashtag_mention_data(filepath, target_col_name):
    try:
        df = pd.read_csv(filepath, header=0, names=['username', target_col_name, 'timestamp'])
        df['datetime'] = pd.to_datetime(df['timestamp'], unit='s')
        return df.drop(columns=['timestamp'])
    except FileNotFoundError:
        st.error(f"ãƒ•ã‚¡ã‚¤ãƒ« '{filepath}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return None

@st.cache_data
def load_influencer_data(filepath):
    try:
        return pd.read_csv(filepath, sep='\t', skiprows=[1])
    except FileNotFoundError:
        return None

def find_growth_breakpoint(df, metric_col):
    if len(df) < 10: return None
    max_increase, breakpoint_idx = -np.inf, None
    for i in range(int(len(df) * 0.1), int(len(df) * 0.9)):
        increase = df[metric_col][i:].mean() - df[metric_col][:i].mean()
        if increase > max_increase:
            max_increase, breakpoint_idx = increase, i
    return df.index[breakpoint_idx] if breakpoint_idx is not None else None

@st.cache_data
def get_hashtag_past_usage(df_ht, end_date):
    """æŒ‡å®šã•ã‚ŒãŸæ—¥ä»˜ä»¥å‰ã®å…¨ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ä½¿ç”¨å›æ•°ã‚’è¨ˆç®—"""
    past_hashtags = df_ht[df_ht['datetime'] < end_date]
    return past_hashtags['hashtag'].value_counts()

# --- UIæç”» ---
st.title("ğŸ’¡ æˆé•·è¦å› åˆ†æ")
st.info("ã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼ãŒæˆé•·ã—ãŸè¦å› ã‚’ã€Œå¤–éƒ¨è¦å› ï¼ˆæœ‰åäººã‹ã‚‰ã®ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ï¼‰ã€ã¨ã€Œå†…éƒ¨è¦å› ï¼ˆãƒˆãƒ¬ãƒ³ãƒ‰ã®å…ˆå–ã‚Šï¼‰ã€ã®è¦³ç‚¹ã‹ã‚‰åˆ†æã—ã¾ã™ã€‚")

# --- ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ ---
df_posts = load_posts_data('output_beauty_category.csv')
df_hashtags = load_hashtag_mention_data('output_hashtags_beauty_parallel.csv', 'hashtag')
df_mentions = load_hashtag_mention_data('output_mentions_all_parallel.csv', 'mention')
df_influencers = load_influencer_data('influencers.txt')

if any(df is None for df in [df_posts, df_hashtags, df_mentions, df_influencers]):
    st.warning("å¿…è¦ãªãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¸€éƒ¨ãŒèª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸã€‚å‡¦ç†ã‚’ä¸­æ–­ã—ã¾ã™ã€‚")
    st.stop()

famous_users_set = set(df_influencers['Username'].unique())

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ ---
st.sidebar.header("åˆ†æå¯¾è±¡ã®é¸æŠ")
user_list = sorted(df_posts['username'].unique())
selected_user = st.sidebar.selectbox("åˆ†æã—ãŸã„ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’é¸æŠ:", options=user_list)
metric_to_analyze = st.sidebar.radio("åˆ†ææŒ‡æ¨™:", ('likes', 'comments'))
analysis_window_days = st.sidebar.slider("æˆé•·ç›´å‰ã®åˆ†ææœŸé–“ï¼ˆæ—¥æ•°ï¼‰", 1, 90, 30)

# --- ãƒ¡ã‚¤ãƒ³ç”»é¢ ---
user_posts_df = df_posts[df_posts['username'] == selected_user].sort_values('datetime').reset_index()
if user_posts_df.empty:
    st.warning("ã“ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
    st.stop()

breakpoint_idx = find_growth_breakpoint(user_posts_df, metric_to_analyze)
if not breakpoint_idx:
    st.warning("æ˜ç¢ºãªæˆé•·ã®è»¢æ›ç‚¹ã‚’æ¤œå‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
    st.stop()

breakpoint_date = user_posts_df.loc[breakpoint_idx, 'datetime']
window_start_date = breakpoint_date - timedelta(days=analysis_window_days)

st.success(f"æˆé•·ã®è»¢æ›ç‚¹ã‚’ **{breakpoint_date.strftime('%Y-%m-%d')}** ã¨æ¨å®šã—ã¾ã—ãŸã€‚")
st.write(f"ã“ã®ç›´å‰ **{analysis_window_days}æ—¥é–“** ({window_start_date.strftime('%Y-%m-%d')} ã‹ã‚‰) ã«ç™ºç”Ÿã—ãŸã‚¤ãƒ™ãƒ³ãƒˆã‚’åˆ†æã—ã¾ã™ã€‚")

# --- ã‚°ãƒ©ãƒ•æç”» ---
st.header("ğŸ“ˆ ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆæ¨ç§»ã¨åˆ†ææœŸé–“")
fig = px.line(user_posts_df, x='datetime', y=metric_to_analyze, markers=True)

# â–¼â–¼â–¼ ä¿®æ­£ç‚¹ â–¼â–¼â–¼
# å‚ç›´ç·šã¨æ³¨é‡ˆã‚’åˆ†é›¢
fig.add_vline(x=breakpoint_date.to_pydatetime(), line_width=3, line_dash="dash", line_color="red")
fig.add_annotation(x=breakpoint_date.to_pydatetime(), y=user_posts_df[metric_to_analyze].max(),
                   text="æˆé•·ç‚¹", showarrow=False, yshift=10, font=dict(color="red"))
# â–²â–²â–² ä¿®æ­£ç‚¹ â–²â–²â–²
                   
fig.add_vrect(x0=window_start_date, x1=breakpoint_date, fillcolor="red", opacity=0.15, line_width=0, annotation_text="åˆ†ææœŸé–“")
st.plotly_chart(fig, use_container_width=True)

st.markdown("---")
st.header("ğŸ“ åˆ†æçµæœ")

# --- 1. å¤–éƒ¨è¦å› ã®åˆ†æ ---
st.subheader("å¤–éƒ¨è¦å› : æœ‰åäººã‹ã‚‰ã®ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆ")
famous_mentions_in_window = df_mentions[
    (df_mentions['mention'] == selected_user) &
    (df_mentions['username'].isin(famous_users_set)) &
    (df_mentions['datetime'] >= window_start_date) &
    (df_mentions['datetime'] < breakpoint_date)
]

if not famous_mentions_in_window.empty:
    st.success(f"**è¦å› å€™è£œ**: åˆ†ææœŸé–“ä¸­ã«ã€ä»¥ä¸‹ã®æœ‰åã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼ã‹ã‚‰ **{len(famous_mentions_in_window)}** å›ã®ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ãŒã‚ã‚Šã¾ã—ãŸã€‚ã“ã‚ŒãŒæˆé•·ã®ãã£ã‹ã‘ã«ãªã£ãŸå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
    merged_mentions = pd.merge(famous_mentions_in_window, df_influencers[['Username', '#Followers']], left_on='username', right_on='Username', how='left')
    st.dataframe(merged_mentions[['datetime', 'username', '#Followers']].rename(columns={'username': 'ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ã—ãŸæœ‰åäºº', '#Followers': 'ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼æ•°'}))
else:
    st.info("åˆ†ææœŸé–“ä¸­ã«ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå†…ã®æœ‰åäººã‹ã‚‰ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ã•ã‚ŒãŸå½¢è·¡ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")


# --- 2. å†…éƒ¨è¦å› ã®åˆ†æ ---
st.subheader("å†…éƒ¨è¦å› : ãƒˆãƒ¬ãƒ³ãƒ‰ã®å…ˆå–ã‚Š")
user_hashtags_in_window = df_hashtags[
    (df_hashtags['username'] == selected_user) &
    (df_hashtags['datetime'] >= window_start_date) &
    (df_hashtags['datetime'] < breakpoint_date)
]
user_hashtags_before_window = df_hashtags[
    (df_hashtags['username'] == selected_user) &
    (df_hashtags['datetime'] < window_start_date)
]
new_hashtags_set = set(user_hashtags_in_window['hashtag'].unique()) - set(user_hashtags_before_window['hashtag'].unique())

if new_hashtags_set:
    past_hashtag_counts = get_hashtag_past_usage(df_hashtags, window_start_date)
    
    pioneering_hashtags = []
    for ht in new_hashtags_set:
        past_usage = past_hashtag_counts.get(ht, 0)
        if past_usage < 50:
            pioneering_hashtags.append({'hashtag': ht, 'past_global_usage': past_usage})
    
    if pioneering_hashtags:
        st.success(f"**è¦å› å€™è£œ**: åˆ†ææœŸé–“ä¸­ã«ã€ä»¥ä¸‹ã®**æ–°ã—ã„/ãƒ‹ãƒƒãƒãªãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°**ã®ä½¿ç”¨ã‚’é–‹å§‹ã—ã¾ã—ãŸã€‚ã“ã‚ŒãŒãƒˆãƒ¬ãƒ³ãƒ‰ã‚’å…ˆå–ã‚Šã—ã€æˆé•·ã«ç¹‹ãŒã£ãŸå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
        df_pioneer = pd.DataFrame(pioneering_hashtags).sort_values('past_global_usage')
        st.dataframe(df_pioneer.rename(columns={'hashtag': 'ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°', 'past_global_usage': 'éå»ã®å…¨ä½“ã§ã®ä½¿ç”¨å›æ•°'}))
    else:
        st.info("åˆ†ææœŸé–“ä¸­ã«ã€æ–°ã—ã„ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’å…ˆå–ã‚Šã—ãŸã¨è¦‹ã‚‰ã‚Œã‚‹ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ã®ä½¿ç”¨ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
else:
    st.info("åˆ†ææœŸé–“ä¸­ã«ã€æ–°ã—ã„ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ã®ä½¿ç”¨ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")