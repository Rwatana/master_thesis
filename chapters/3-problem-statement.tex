\chapter{問題設定}
本章では，本研究が扱うデータと予測タスクを整理し，時系列異種混合グラフに基づくランキング学習問題として定式化する。
特に，(i) マルチモーダルな投稿コンテンツ，(ii) ユーザー間関係を表すグラフ構造，(iii) 時系列変化を同時に扱う点を明確にする。

\section{対象とするデータ}
本研究で扱うのは，SNSプラットフォームから収集された大規模なマルチモーダルデータである。
インフルエンサーマーケティングに関わるデータは，概ね以下の要素を含む。

\subsection{データの特徴}
\begin{enumerate}
    \item 画像，テキスト，数値など異なるモダリティの情報が混在している
    \item ユーザー間のフォロー関係やメンションなど，複雑なネットワーク構造を持っている
    \item 時間の経過とともに投稿や関係性が変化する時系列データである
    \item 過去のデータであるため，未来時点の正解（エンゲージメント）が確定している
\end{enumerate}

本研究では特に，上記1および2の複合的な情報がインフルエンサーの影響力を形成する状況を想定する。
このようなデータが得られる例としては，Instagramの投稿データ，Twitterの拡散ログ，YouTubeの視聴者推移データなどが挙げられる。
本研究では，既存研究で用いられているInstagramデータセットを用いて追試と分析を行うため，以下でデータの内容と本研究目的との適合を述べる。

\subsection{データの詳細}
本研究で扱うInstagramデータは，インフルエンサーの活動記録であり，マルチモーダルデータの一種である。
このデータは，ユーザー，投稿，タグなどが相互に関連し合う異種混合グラフとして表現できる。
データには，投稿画像の輝度や色温度などの画像特徴，キャプションのテキスト長などのテキスト特徴，ハッシュタグ数やメンション情報といった行動・関係性の情報が含まれる。
また，「いいね」数やコメント数などの反応量も含まれるが，本研究ではこれらを将来予測の正解ラベルとして扱い，モデル入力には直接用いない（詳細は\ref{sec:task_link}節および\ref{sec:formalization}節で述べる）。
以上より，本データはコンテンツの内容とユーザー間のつながりを同時に含むため，「誰がなぜ人気になるのか」を分析するという目的に適合する。

\subsection{データセット選定の妥当性と限界}
本研究で使用するInstagram Influencer Dataset \cite{Kim2023InfluencerRank} は，本来インフルエンサーの興味・関心に基づくカテゴリ分類を目的として構築されたものである。
そのため，本研究が目指す時系列での影響力予測（Influencer Rank）および青田買いシステムの構築を行う上では，以下の制約が存在する。

\begin{enumerate}
    \item 完全なソーシャルグラフの欠如:
    本データセットにはフォロー・フォロワー関係の完全なグラフが含まれていない。
    これに対し本研究では，投稿内のメンション（@usertags）やコメントの共起関係などから擬似的なネットワークを構築し，
    これをユーザー間の関係性の代替指標として利用することで対処する（具体的な構築方法は第6章で述べる）。

    \item データの適時性とトレンドの乖離:
    収集期間が2017年であり，現在のトレンド（短尺動画の台頭など）とは乖離がある。
    ただし，本研究では「投稿コンテンツとネットワーク形成がエンゲージメントに影響する」という基本的なメカニズムに注目し，
    その有効性が一定程度保たれると仮定する。
\end{enumerate}

これらの制約はあるものの，本データセットは画像・テキスト・数値が紐づいた大規模なマルチモーダルデータであり，
かつ過去データであるため未来時点の正解ラベル（実際の反応量）が確定している。
この点において，本研究で扱う予測モデルおよびXAIによる要因分析手法を定量的に評価するための検証環境として適していると判断し採用する。

\section{データと予測タスクの結びつき}
\label{sec:task_link}
本研究では，インフルエンサーの成長予測において，マルチモーダル性とグラフ構造が将来の影響力に影響を与えると仮定する。
単一の静的指標（例：フォロワー数）だけに注目すると，購入フォロワーや不正アカウント等により指標が歪む可能性がある。
そこで本研究は，投稿コンテンツ（画像・テキスト）や行動・関係性（ハッシュタグ，メンション，共起等）といった複合的な情報に基づき，
翌月の影響力をどの程度予測できるかを検証する。

また，実務上は評価指標の仕様（可視化される反応指標など）が変化し得る。
本研究の枠組みでは，将来予測の入力として過去のエンゲージメント値そのものを用いず，コンテンツおよび関係性に基づく情報から予測することを重視する。
これにより，可観測な指標の変化があっても，コンテンツの力に基づく評価・予測へ接続しやすいことが期待される。

\section{問題の定式化}
\label{sec:formalization}
本節では，インフルエンサーの影響力予測問題を数理的に定義する。
問題を，時系列異種混合グラフデータを用いたランキング学習タスクとして定式化する。

\subsection{入力と出力の定義}
時点 $t$（例：月）における異種混合グラフを $G_t=(V_t,E_t)$ とし，各ノードの特徴行列を $X_t$ とする。
ここで $V_t$ はノード集合（インフルエンサー，一般ユーザー，ハッシュタグ，画像オブジェクト等），$E_t$ はエッジ集合（メンション，共起等）を表す。
インフルエンサーノード集合を $I_t \subseteq V_t$ とし，本研究のランキング対象は $I_t$ に限定する。

観測窓長を $T$ とし，予測対象月を $t+1$ とする。
予測モデル $F$ は過去 $T$ 期間の系列 $\{(G_{t-T+1},X_{t-T+1}),\dots,(G_t,X_t)\}$ を入力として，
各インフルエンサー $u\in I_t$ に対する翌月の予測スコア $\hat{s}_{u,t+1}$ を出力する：
\[
\hat{s}_{u,t+1} = F\!\left((G_{t-T+1},X_{t-T+1}),\dots,(G_t,X_t); \Theta\right),
\]
ここで $\Theta$ はモデルの学習可能パラメータである。

\subsection{影響力（エンゲージメント）指標}
本研究では，時点 $t$ におけるインフルエンサー $u$ の影響力（エンゲージメント）を，
いいね数とコメント数の合計をフォロワー数で正規化した値として定義する：
\[
y_{u,t} = \frac{\mathrm{likes}_{u,t} + \mathrm{comments}_{u,t}}{\mathrm{followers}_{u,t}}.
\]
この $y_{u,t}$ は予測の正解ラベルとして用いる。
一方で，入力特徴 $X_t$ には $y_{u,t}$ を直接含めず，投稿コンテンツや関係性に由来する特徴に基づいて将来スコアを推定する。

\subsection{損失関数による最適化（ListMLE）}
本研究の目的は，将来の影響力が高いインフルエンサーを相対順位として正確に推定することである。
したがって回帰誤差ではなく，ランキング学習として損失関数を設計する。

学習では，対象月 $t$ を固定したときのインフルエンサー集合 $I_t$ から，長さ $L$ のリスト（クエリ）$Z_i$ をサンプリングする：
\[
Z_i = \{u_{i1},\dots,u_{iL}\} \subseteq I_t.
\]
モデルは各 $u\in Z_i$ に対し翌月の予測スコア $\hat{s}_{u,t+1}$ を出力する。
以降，記号を簡略化して $\hat{s}_{iu}=\hat{s}_{u,t+1}$ と書く。

翌月の正解ラベル $y_{u,t+1}$ に基づき，リスト $Z_i$ 上の正解順序（置換）$\pi_i$ を
\[
y_{i\pi_i(1)} \ge y_{i\pi_i(2)} \ge \cdots \ge y_{i\pi_i(L)}
\]
を満たすように定める（同値はランダムにタイブレークする）。
ここで $y_{i\pi_i(k)}$ は $Z_i$ 内の要素 $u_{i\pi_i(k)}$ の翌月ラベル $y_{u_{i\pi_i(k)},t+1}$ を表す。

ListMLE は，予測スコア $\hat{s}_i=\{\hat{s}_{iu}\}_{u\in Z_i}$ に対して，
Plackett--Luce モデルで正解順序 $\pi_i$ が生成される確率を
\[
P(\pi_i \mid \hat{s}_i)
= \prod_{k=1}^{L}
\frac{\exp\bigl(\hat{s}_{i\pi_i(k)}\bigr)}
{\sum_{j=k}^{L}\exp\bigl(\hat{s}_{i\pi_i(j)}\bigr)}
\]
と定義し，その負の対数尤度を損失として最小化する：
\[
\mathcal{L}_{\mathrm{ListMLE}}(\Theta)
= \frac{1}{m}\sum_{i=1}^{m} \Bigl(-\log P(\pi_i \mid \hat{s}_i)\Bigr)
= \frac{1}{m}\sum_{i=1}^{m}\sum_{k=1}^{L}
\left[
\log\!\left(\sum_{j=k}^{L}\exp(\hat{s}_{i\pi_i(j)})\right)
-\hat{s}_{i\pi_i(k)}
\right].
\]
ここで $m$ は学習で用いるリストの総数である。
本研究では，ランキング最適化を採用する先行研究に倣い list-wise learning-to-rank の枠組みで学習するが，
0--1 損失は微分不可能であるため，実装可能な滑らかな代理損失として ListMLE を用いる。
また，リスト $Z_i$ は実装上ランダムサンプリングで構成する（例：$L=10$）。
