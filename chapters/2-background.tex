\chapter{前提知識}
本研究で扱う課題は,(i) グラフ構造（ユーザー間関係や投稿内容の関係性）,(ii) 時系列変化（成長・バズ・関係性の変動）,(iii) 深層学習モデルの説明可能性（XAI）という複数要素が同時に現れる点に特徴がある。
本章では,提案手法の理解に必要な基礎として,グラフニューラルネットワーク,時系列モデルと注意機構,説明可能AIの代表的枠組み,ならびに評価指標を整理する。

\section{グラフニューラルネットワーク（GNN）}
\subsection{グラフ表現}
グラフは $G=(V,E)$ と表し,$V$ はノード集合,$E$ はエッジ集合である。
ノード数を $n=|V|$ とすると,隣接行列 $A\in\{0,1\}^{n\times n}$ は
$(i,j)\in E$ のとき $A_{ij}=1$（それ以外は0）で定義される。
各ノード $v$ は特徴ベクトルを持ち,特徴行列を $X\in\mathbb{R}^{n\times d}$ とする。

本研究の対象では,インフルエンサー・一般ユーザー・ハッシュタグ・画像オブジェクト等の異種ノードが存在し,
またフォロー・メンション・共起など複数種類の関係が現れるため,グラフは一般に異種（heterogeneous）である。
前提知識として本節では,まず標準的な同種グラフ（単一関係種別）を想定したGNNを述べ,異種性や複数関係種別の扱いは後述（第4章および第5章）で整理する。
なおSNSでは有向関係が現れることが多いが,本章では説明の簡潔化のため隣接行列 $A$ による表現を用い,有向性の影響は後段で補足する。

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.55\linewidth]{figures/heterogenous_graph.png}
    \caption{異種混合グラフの例（ノード種別・関係種別を含む）}
    \label{fig:hetero_graph_bg}
\end{figure}

\subsection{GCNによる近傍集約}
GNNの基本的な考え方は,各層で近傍ノードの情報を集約し,変換して次層の表現を得ることである。
代表例として,Kipf \& Welling によるGraph Convolutional Network（GCN）は,層 $l$ のノード表現
$H^{(l)}\in\mathbb{R}^{n\times d_l}$ から次層 $H^{(l+1)}$ を次式で更新する \cite{kipf2017gcn}：
\begin{align}
\tilde{A} &= A + I,\quad \tilde{D}_{ii} = \sum_j \tilde{A}_{ij}, \\
\hat{A} &= \tilde{D}^{-\frac{1}{2}}\tilde{A}\tilde{D}^{-\frac{1}{2}}, \\
H^{(l+1)} &= \sigma\!\left(\hat{A} H^{(l)} W^{(l)}\right).
\end{align}
ここで,$I$ は単位行列,$\tilde{D}$ は次数行列,$W^{(l)}$ は学習可能パラメータ,
$\sigma(\cdot)$ は非線形活性化関数（例：ReLU）である。通常,入力特徴を $H^{(0)}=X$ とおくことで,
各層の更新によりグラフ構造を反映した表現を得る。
この更新により,ノードは自身と近傍から情報を取り込み,グラフ構造を反映した表現を獲得できる。

なお,GCNはGNNの一例であり,より一般的にはメッセージパッシングとして統一的に理解できる \cite{gilmer2017mpnn}。
本研究では,各時点で構築したグラフに対してGNN（GCN）を適用し,時点ごとの空間的（構造的）表現を得る。
例えば,\ref{fig:gcn_bg}にGCNの近傍集約の概念図を示す。これは,Jerryというユーザーの情報が集約される様子を表しており,
メンションやハッシュタグ共起で結ばれた近傍ノードから情報を集約し,自身の表現を更新する様子を表している。
Jerryが投稿で使用したハッシュタグや,メンションした他ユーザーの情報,投稿したオブジェクト(犬, 猫 etc)も,間接的に集約されることになる。

\begin{figure}[htbp]
    \centering
    \includegraphics[width=1\linewidth]{figures/gcn.png}
    \caption{GCNによる近傍集約の概念図}
    \label{fig:gcn_bg}
\end{figure}

\section{時系列情報の処理と注意機構}
\subsection{時系列データの統合（RNN/LSTM）}
隠れ状態を持つ再帰型ニューラルネットワーク（RNN）は時系列データの処理に広く用いられる\cite{elman1990rnn}。
本研究では，各時点でGNNにより得たノード表現 $R_t$ を時系列方向に統合し，将来スコアを推定するためにRNNを用いる。
RNNには複数の実装があり，長期依存を扱うためにLSTM\cite{hochreiter1997lstm}やGRU\cite{cho2014gru}が用いられる。
先行研究（InfluencerRank）に合わせ，本研究では時系列統合にLSTMを採用する（第4章でモデル仕様を確定し，第5章で説明手法を導入する）。

時点 $t$ におけるGNNの出力（ノード表現）を $R_t$ とすると,
再帰型ニューラルネットワーク（RNN）により時系列方向へ統合し,隠れ状態 $S_t$ を更新する：
\begin{align}
S_t = \mathrm{RNN}(R_t, S_{t-1}).
\end{align}

RNNには複数の実装があり,長期依存を扱うためにLSTM \cite{hochreiter1997lstm} やGRU~\cite{cho2014gru} が用いられることが多い。
本研究では時系列統合にLSTMを採用する。
また,InfluencerRank型モデルはGNNで得た各時点表現を再帰モデルと注意機構で統合し,最終的に将来スコアを推定する（詳細は第4章および第5章で述べる）。

\begin{figure}[htbp]
    \centering
    \includegraphics[width=1\linewidth]{figures/model_flow.png}
    \caption{時系列グラフ処理の流れ（各時点：GNN,時系列統合：RNN/LSTM,重要時点の強調：Attention）}
    \label{fig:model_flow}
\end{figure}
TODO: 図のキャプションを修正してください（Attention→Temporal Attention）


\subsection{注意機構（Temporal Attention）}
全ての時点が予測へ等しく寄与するとは限らない。
例えば,特定月の急成長やバズ,コラボ関係の変化が将来スコアに強く影響することがある。
インフルエンサーの影響力は時間とともに変化するため,時系列に応じて重要度が変わる。例えば昔の影響度が高い重鎮のような人もいれば,最近急成長している新進気鋭のインフルエンサーもいる。
前者であれば過去の情報が重要であり,後者であれば最近の情報が重要になる。
したがって,複数時点の情報を統合する必要がある。
そこで,各時点の隠れ状態 $S_t$ に対して重み $\alpha_t$ を学習し,重要な時点を強調する注意機構を用いる \cite{bahdanau2015attention}。
一般的な定式化の一例として,
\begin{align}
e_t &= v_a^\top \tanh(W_a S_t + b_a), \\
\alpha_t &= \frac{\exp(e_t)}{\sum_{\tau=1}^{T}\exp(e_\tau)}, \\
S_{\mathrm{final}} &= \sum_{t=1}^{T} \alpha_t S_t
\end{align}
を用いることで,時系列全体から予測に有用な情報を集約できる。
ここで $W_a, v_a, b_a$ は学習可能パラメータである。

\section{説明可能AI（XAI）}
XAIとは,AIモデルの予測根拠を人間に理解可能な形で提供する技術群を指す。
深層学習は高い表現能力を持つ一方で,予測根拠がブラックボックス化しやすい。
特に,マーケティング分野では,予測結果の解釈性が重要であり,XAI技術の活用が求められる \cite{Gunning2019,Arrieta2020XAI}。それは,いくら機械学習モデルが高精度な予測を提供しても,その予測がどのような根拠に基づいているかが不明確であれば,意思決定に活用しづらいためである。
新しいインフルエンサーを発掘する際にも,単に「このユーザーが伸びる」と予測されるだけでなく,「なぜそのように予測されたのか」を理解することが重要である。伸びた要因が明確で,再現可能であれば,他のユーザーにも同様の戦略を適用できるからである。また,その伸び方が一時的な流行りによるものか,本人の努力やコンテンツの質によるものかを理解することも重要である。
% ===== 2.3 冒頭追記：本研究での説明の評価軸（貼り付け可） =====
本研究では，説明の良し悪しを主観的な可視化だけで判断しないために，少なくとも以下の観点を区別して扱う．
(1) 忠実性（faithfulness）: 説明で重要とされた要素を操作したとき，予測が想定通り変化するか（score impact により検証）．
(2) 簡潔性（sparsity）: 少数要素に説明がまとまっているか（マスクの L1 や有効要素数で評価）．
(3) 安定性（stability）: 初期値や対象サンプルの違いで説明が大きく崩れないか（順位相関や分散で評価）．
(4) 比較可能性（comparability）: 月次で「どの月が効いたか／何が効いたか」を同一尺度で比較できるか（集約・正規化の方法を明示）．

\subsection{グラフ予測における説明の考え方}
XAIの中でも,グラフニューラルネットワーク（GNN）に対する説明可能性の研究が近年盛んである。
GNNはノード間の複雑な関係性を捉えるために用いられるが,その予測根拠はさらにブラックボックス化しやすい。
したがって,予測モデルに対する説明可能性の付与が求められる \cite{Gunning2019,Arrieta2020XAI}。

グラフ予測に対する説明は,大きく
(1) 特徴量（ノード属性）の寄与と,
(2) 構造（どのエッジ／どの部分グラフが重要か）
の二面から捉えられる。
本研究はこの両者を同一枠組みで扱い,さらに時系列（どの月が効いたか）まで比較可能にすることを目指す。

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.55\linewidth]{figures/graph_xai.png}
    \caption{グラフ予測における説明の対象：特徴量・構造}
    \label{fig:graph_xai}
\end{figure}

\subsection{マスク最適化に基づく説明（GNNExplainer系）}
\subsubsection{背景}
グラフ予測に対する説明手法として,マスク最適化に基づくアプローチがある。
これは,予測に重要な要素（特徴量・エッジ）を選択するマスクを学習し,予測に寄与する要素をコンパクトに抽出するタイプの説明である。
代表例として,ノード分類タスクに対するGNNExplainer \cite{Ying2019GNNExplainer} がある。
本節では,この枠組みの概要と損失関数を述べる。

\subsubsection{概要}
本研究では,最適化に基づいて予測をできるだけ維持しつつ,入力（特徴量・エッジ）を疎に残すマスクを学習し,予測に寄与する要素をコンパクトに抽出するタイプの説明を採用する。
マスクとは、予測に重要な要素を選択するための重み付けであり,0から1の範囲で表される。0に近い値はその要素が予測にほとんど寄与しないことを示し,1に近い値はその要素が予測に大きく寄与することを示す。
代表例であるGNNExplainerは,エッジマスク $m_E\in[0,1]^{|E|}$ と特徴マスク $m_X\in[0,1]^{d}$ を導入し,マスク後の入力でも予測をできるだけ保つ一方で,マスクを疎にするよう学習する \cite{Ying2019GNNExplainer}。マスクの値が疎になるということは,少数の特徴量・少数のエッジで予測が説明できることを意味する。

直観的には,
\begin{itemize}
  \item 忠実性（fidelity）: マスク後も予測が大きく変わらない（説明が予測に整合する）
  \item 簡潔性（sparsity）: 少数の特徴・少数のエッジで説明できる（重要な特徴のみが残り不要な特徴が消えたということを意味する）
\end{itemize}
を両立するように,マスクを最適化する。
時系列グラフモデルへの適用方法,ならびに特徴量・エッジの符号付き影響度の定義と計算は第5章で詳述する（関連する先行枠組みの整理は第4章で述べる）。

\subsubsection{損失関数}

GNN-Explainer~\cite{Ying2019GNNExplainer} では、本来のタスクがノード分類であることを想定しており、損失関数は以下のように定義されている。
\begin{align}
\mathcal{L} = \mathcal{L}_{\text{pred}} + \lambda_1 \|m_E\|_1 + \lambda_2 \|m_X\|_1
\end{align}
ここで、$\mathcal{L}_{\text{pred}}$ は予測損失（例えばクロスエントロピー損失）、$\|m_E\|_1$ および $\|m_X\|_1$ はそれぞれエッジマスクと特徴マスクのL1ノルムであり、$\lambda_1$ および $\lambda_2$ は正則化パラメータである。
この損失関数は、予測性能を維持しつつ、マスクを疎にすることを目的としている。


\section{評価指標}
本研究は将来有望なインフルエンサーの順位付けを目的とするため,
回帰誤差だけでなくランキング指標で性能を評価する。
本節では代表的な指標としてNDCGとRBPを述べる。

\subsection{NDCG（Normalized Discounted Cumulative Gain）}
NDCGは,上位に関連度の高いアイテムが配置されるほど高く評価する指標である \cite{jarvelin2002ndcg}。
順位 $i$ の関連度を $rel(i)$ とし,ゲイン関数 $g(\cdot)$ を用いると,
\begin{align}
DCG@k &= \sum_{i=1}^{k}\frac{g(rel(i))}{\log_2(i+1)}, \\
NDCG@k &= \frac{DCG@k}{IDCG@k}
\end{align}
と定義される。ここで $IDCG@k$ は理想順位における $DCG@k$ である。
$g(rel)=rel$ あるいは $g(rel)=2^{rel}-1$ など複数の流儀があるため,
本研究で採用する関連度設計とゲイン関数は実験設定（第6章）で明記する。

\subsection{RBP（Rank-biased Precision）}
RBPは,ユーザが上位から確率 $p$ で閲覧を継続するという行動モデルに基づく指標である \cite{moffat2008rbp}。
\begin{align}
RBP = (1-p)\sum_{i=1}^{N} rel_i\, p^{i-1}
\end{align}
で定義される。ここで $N$ は評価対象のランキング長である。
$p$ が大きいほど下位順位までを広く評価し,$p$ が小さいほど上位を重視する。
マーケティングでは上位候補の抽出が重要であるため,本研究でもRBPを用いて上位重視の評価を行う。

\subsection{Pearson相関係数}
Pearson相関係数は,予測値と真値の線形関係を評価する指標である。
\begin{align}
r = \frac{\sum_{i=1}^{N}(y_i - \bar{y})(\hat{y}_i - \bar{\hat{y}})}{\sqrt{\sum_{i=1}^{N}(y_i - \bar{y})^2}\sqrt{\sum_{i=1}^{N}(\hat{y}_i - \bar{\hat{y}})^2}}
\end{align}
で定義される。ここで $y_i$ は真値,$\hat{y}_i$ は予測値,$\bar{y}$ および $\bar{\hat{y}}$ はそれぞれの平均値である。
Pearson相関係数は $-1$ から $1$ の範囲を取り,$1$に近いほど強い正の相関を示す。
本研究では,予測値と真値の全体的な一致度を評価するために用いる。

\subsection{Spearmanの順位相関係数}
Spearmanの順位相関係数は,予測値と真値の順位関係を評価する指標である。
\begin{align}
\rho = 1 - \frac{6\sum_{i=1}^{N}d_i^2}{N(N^2 - 1)}
\end{align}
で定義される。ここで $d_i$ は各アイテムの真値順位と予測値順位の差である。
Spearmanの順位相関係数は $-1$ から $1$ の範囲を取り,$1$に近いほど強い正の順位相関を示す。
本研究では,予測値と真値の順位関係の一致度を評価するために用いる。

